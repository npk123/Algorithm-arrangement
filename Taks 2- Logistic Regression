# 1、逻辑回归与线性回归的联系与区别

联系：

线性回归：根据几组已知数据和拟合函数训练其中未知参数，使得拟合损失达到最小。然后用所得的拟合函数进行预测。 

逻辑回归：和拟合函数训练其中未知参数使得对数似然函数最大。然后用所得的拟合函数进行二分类。 

两者都是回归，步骤和原理看起来相似。



区别：
    1.线性回归要求变量服从正态分布，logistic回归对变量分布没有要求。
    2.线性回归要求因变量是连续性数值变量，而logistic回归要求因变量是分类型变量。
    3.线性回归要求自变量和因变量呈线性关系，而logistic回归不要求自变量和因变量呈线性关系
    4.logistic回归是分析因变量取某个值的概率与自变量的关系，而线性回归是直接分析因变量与自变量的关系

总之, logistic回归与线性回归实际上有很多相同之处，最大的区别就在于他们的因变量不同，其他的基本都差不多，
正是因为如此，这两种回归可以归于同一个家族，即广义线性模型（generalized linear model）。这一家族中的模
型形式基本上都差不多，不同的就是因变量不同，如果是连续的，就是多重线性回归，如果是二项分布，就是logistic回归。
logistic回归的因变量可以是二分类的，也可以是多分类的，但是二分类的更为常用，也更加容易解释。所以实际中最为常用的就是二分类的logistic回归。

2、 逻辑回归的原理



3、逻辑回归损失函数推导及优化



4、 正则化与模型评估指标



5、 逻辑回归的优缺点

优点

   1) LR是以概率的形式输出结果，不只是0和1的判定； 
   2) LR的可解释强，可控性高； 
   3) 训练快，feature engineering之后效果赞； 
   4) 因为结果是概率，可以做ranking model； 
   5) 添加feature简单。 
   
LR的应用场景很多哈： 

   1) CTR预估、推荐系统的learning to rank； 
   2) 一些电商搜索排序基线； 
   3) 一些电商的购物搭配推荐； 
   4) 新闻app排序基线。

6、 样本不均衡问题解决办法

样本太大怎么处理？ 

   1) 对特征离散化，离散化后用one-hot编码处理成0,1值，再用LR处理会较快收敛； 
   2) 如果一定要用连续值的话，可以做scaling； 
   3) 工具的话有 spark Mllib，它损失了一小部分的准确度达到速度的提升； 
   4) 如果没有并行化平台，想做大数据就试试采样。需要注意采样数据，最好不要随机取，可以按照日期/用户/行为，来分层抽样。 

怎么使样本平衡？ 

   1) 如果样本不均衡，样本充足的情况下可以做下采样——抽样，样本不足的情况下做上采样——对样本少的做重复； 
   2) 修改损失函数，给不同权重。比如负样本少，就可以给负样本大一点的权重； 
   3) 采样后的predict结果，用作判定请还原。

7.  sklearn参数
